{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.datasets import make_regression\n",
        "import joblib\n",
        "\n",
        "# Generate a simple regression dataset\n",
        "X, y = make_regression(n_samples=100, n_features=1, noise=0.1)\n",
        "\n",
        "# Train a linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Serialize the model to a file\n",
        "joblib.dump(model, 'model.pkl')"
      ],
      "metadata": {
        "id": "Rj9xtf1tB6CI",
        "outputId": "134a92f2-2c0d-46e4-d232-72d2e534281d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "from threading import Thread\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Assuming your model is saved in the same directory and named 'model.pkl'\n",
        "model = joblib.load('model.pkl')\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    data = request.get_json(force=True)\n",
        "    features = data['features']\n",
        "    prediction = model.predict([features])\n",
        "    return jsonify({'prediction': prediction.tolist()})\n",
        "\n",
        "\n",
        "def run_app():\n",
        "    # Specifying the port and host is optional. By default, Flask runs on port 5000.\n",
        "    # Setting use_reloader=False to prevent the app from being reloaded twice\n",
        "    app.run(debug=True, use_reloader=False, port=5000)\n",
        "\n",
        "# Start the Flask app in a separate thread\n",
        "thread = Thread(target=run_app)\n",
        "thread.start()"
      ],
      "metadata": {
        "id": "mj32cuDyB5_X",
        "outputId": "40733f29-fefc-41cf-ccfb-da681f84a5fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# The URL for the predict endpoint\n",
        "url = 'http://127.0.0.1:5000/predict'\n",
        "\n",
        "# Example data to send to the predict endpoint\n",
        "data = {'features': [1.23]}\n",
        "\n",
        "# Make a POST request and print the response\n",
        "response = requests.post(url, json=data)\n",
        "print(response.json())"
      ],
      "metadata": {
        "id": "6ZDLNInYB59B",
        "outputId": "458048ff-c787-4814-901d-7fc88795131f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [12/Mar/2024 19:09:32] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'prediction': [75.17954478116764]}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}